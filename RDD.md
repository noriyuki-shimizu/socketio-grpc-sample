## AIチャットアプリ実行計画書

### 1. プロジェクト目的
- Nuxt v4 を用いたモダンなチャットUI上で、Gemini Pro Vision (Google AI SDK) の回答をリアルタイムに表示する。
- フロントエンドとバックエンドを同一デバイスで完結させ、開発・デモ運用をローカルのみで行えるようにする。
- 大容量(最大500MB)の画像を扱いつつ、レスポンス遅延を最小化し、ユーザーに滑らかな対話体験を提供する。

### 2. 要件サマリ
| 区分 | 内容 |
| --- | --- |
| AI SDK | Gemini Pro Vision を Google公式 SDK 経由で利用。サーバー側でストリーミング受信しフロントへ逐次送信。 |
| フロント | Nuxt v4 + TypeScript。リアルタイム描画のため Socket.io クライアントを組み込み、Tailwind CSS などでモダンUIを構築。 |
| 通信方式 | フロント⇔バック間は Socket.io、バック⇔Gemini は gRPC もしくはそれに準じたストリーミングAPI。 |
| 画像要件 | ユーザーアップロードは500MBまで。送信前に WebP 圧縮 (デフォルトQ=85、高品質Q=95) を必須化。 |
| 追加変換 | バックエンドで WebAssembly ベースの軽量変換を実施し、Gemini へ渡す最適フォーマットを生成。 |
| ローカル完結 | Nuxt フロントとバックエンド(gRPC + WASM + Gemini SDK 呼び出し)を同一マシンで起動できれば要件充足。 |

### 3. 成功指標 (SLO の目安)
- 95%タイルのラウンドトリップレイテンシ ≤ 1.5 秒 (テキストのみ)
- 画像送信時も初回部分応答まで ≤ 3 秒
- Socket.io 再接続成功率 99% 以上
- 1 セッションあたりメモリ消費 250MB 以内 (画像バッファ除外)

### 4. システム全体像
1. Nuxt v4 フロントでユーザー入力/画像を受付→Web Worker で WebP 変換。
2. Socket.io でローカル Node/gRPC ゲートウェイへ送信 (モードメタ: `mode=fast|quality`).
3. Node サーバーは WASM 変換マイクロサービスへ渡し、更なる軽量化/検証を実施。
4. gRPC サービスが Gemini Pro Vision SDK を呼び出し、ストリーミングレスポンスを受信。
5. 受信チャンクを Socket.io namespace へ逐次 push→Nuxt 側でステータス更新。

### 5. フロントエンド計画
- **技術スタック**: Nuxt v4 (app router) + TypeScript + Pinia (会話状態) + Socket.io client + Tailwind CSS + Headless UI。
- **ページ構成**: `/chat` 単一画面 (レイアウト: サイドバー/履歴 + メインチャット + 入力パネル)。
- **リアルタイムUI**: ストリーミングチャンクを細分化して即描画、読み込みインジケータやタイピングドットを実装。
- **画像処理フロー**: ファイル選択→Web Worker へ転送→WebP 変換 (デフォルトQ=85)。トグル切替でQ=95再変換し、差分のみ送信。大容量ファイルはチャンク化して Socket.io へ送信。
- **アクセシビリティ/モダンUI**: キーボード操作、ハイコントラストテーマ、レスポンシブ対応を Tailwind トークンで統一。

### 6. リアルタイム通信レイヤー
- Socket.io namespace を `chat:stream` と `chat:control` に分離し、制御メッセージと本文チャンクを切り離して遅延を低減。
- 接続復旧時に最後の message_id 以降を再送する replay API を提供。
- 圧縮した画像は Socket.io Binary Ack を活用し、アップロード成功/失敗を即時通知。

### 7. バックエンド計画
- **プロセス構成**: Node.js gRPC ゲートウェイ + WASM 画像変換サービス + Gemini SDK 呼び出しレイヤーを同一マシン内で起動。
- **gRPC API (例)**:
	```proto
	service ChatService {
		rpc StreamReply (ChatRequest) returns (stream ChatChunk);
	}
	message ChatRequest {
		string session_id = 1;
		string mode = 2; // fast | quality
		bytes image_webp = 3;
		string prompt = 4;
	}
	```
- **WASM 変換**: WebPの検証、必要に応じた解像度変更、メタデータ抽出を数百ms以内で完了させ、Gemini へ渡す前に帯域とレイテンシを抑制。
- **Gemini SDK 連携**: Streaming API を使用し、チャンク受信時点で Socket.io に中継。失敗時は指数バックオフで再試行。
- **ローカル完結**: すべてのサーバープロセスを `npm run dev:*` 系コマンドで同一デバイスにて起動可能にする。

### 8. 画像・パフォーマンス方針
- 入力画像は必ずクライアント側で WebP 変換。500MB超過は即リジェクト。
- デフォルト高速モード(Q=85)でアップロード。UIトグルで Q=95 に切り替えた場合のみ再変換。
- サーバー側 WASM ではメモリマップIOを利用し、コピーコストを削減。Gemini へは要求解像度に応じた最適サイズを送信。
- メトリクス: 圧縮時間、変換時間、gRPC 往復時間を OpenTelemetry 互換で記録。

### 9. 環境変数運用とセキュリティ
- `.env` は Git 管理外、`.env.sample` のみ commit。フォーマットは `ENV_VAR="説明"` を徹底。
- 初期想定変数:
	```
	GEMINI_API_KEY="Gemini Pro Vision 用のAPIキー"
	SESSION_SECRET="Socket.io セッション署名用のランダム文字列"
	```
- 変数追加時のフロー:
	1. `.env.sample` に `ENV_VAR="説明"` 形式で追記。
	2. `RDD.md` または該当ドキュメントに用途を追記。
	3. PR テンプレのチェック項目 `- [ ] 追加環境変数を .env.sample に追記済み` を必ずオンにする。

### 10. 開発フェーズとマイルストーン
1. **要件確定 (本書)**: 画像制約・モード仕様・環境変数運用を確定。
2. **アーキ試作**: Socket.io + gRPC + Gemini SDK のエンドツーエンド最小構成をローカルで実証。
3. **UI/UX 実装**: Nuxt ページ・コンポーネント、Web Worker 圧縮、ストリーミング描画を実装。
4. **性能チューニング**: WASM 変換最適化、チャンクサイズ調整、メトリクス収集整備。
5. **総合テスト**: 画像サイズ別の回帰テスト、ネットワーク遅延シミュレーション、ローカルでの負荷試験。

### 11. テスト / 検証計画
- **ユニット**: Web Worker 圧縮ロジック、gRPC モデル呼び出し、Socket.io イベントハンドラ。
- **統合**: 画像アップロード→Gemini 応答までのエンドツーエンドをモード別に検証。
- **性能**: 100MB/250MB/500MB ケースで圧縮時間とストリーム遅延を測定。WASM 変換は 300ms 以内を目標。
- **回帰**: PR 時に `.env.sample` 変更有無を自動チェックする lint スクリプトを追加検討。

### 12. リスクと対応
- **500MB 画像の処理負荷**: クライアント/サーバー双方でストリーム処理を採用し、ピークメモリを抑制。必要であればアップロード前にファイル分割を促す。
- **Gemini API レイテンシ/失敗**: 失敗時の再試行、およびユーザー通知を行う。ローカル環境のネットワーク制約を事前に計測。
- **環境変数漏洩**: `.env` は常に `.gitignore` 登録を確認し、PR テンプレチェックでヒューマンエラーを防止。
- **モード切替の UX**: 再圧縮コストが高い場合に備え、変換待ち表示とキャンセル操作を提供。

### 13. 未決事項 / 今後の検討
- Gemini Pro Vision のモデルバージョン固定方針 (最新安定版かロングサポート版か)。
- ローカル端末スペックの最低要件 (CPU/GPU/RAM) 整理。
- `.env.sample` への将来的な追加変数(代理キー、Proxy設定など)が必要になった際のレビュープロセス詳細。
